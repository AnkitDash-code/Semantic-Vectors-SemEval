{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ],
      "metadata": {
        "id": "Ls1UPn_tlIK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXapiv1YhQwN"
      },
      "outputs": [],
      "source": [
        "!pip install transformers>=4.40.0 torch>=2.0.0 accelerate scikit-learn pandas numpy torch-lr-finder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    BertModel,\n    Trainer,\n    TrainingArguments,\n    DataCollatorWithPadding,\n    get_cosine_schedule_with_warmup,\n    EarlyStoppingCallback\n)\nfrom google.colab import drive\nfrom torch.utils.data import Dataset\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nimport random\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\ndrive.mount('/content/gdrive')\nDRIVE_MODEL_DIR = '/content/gdrive/MyDrive/SemevalModels/bitnet_polarization_improved'\n\n# Define device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-AjKfOhtRg",
        "outputId": "a0cb7088-e121-43af-a1ba-13e70bbd88df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_multilingual_data(data_dir, languages=None, split='train'):\n",
        "    \"\"\"\n",
        "    Load data from multiple language files\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to directory (e.g., '/content/gdrive/MyDrive/subtask1/train')\n",
        "        languages: List of language codes (e.g., ['eng', 'arb', 'deu']) or None for all\n",
        "        split: 'train' or 'dev'\n",
        "\n",
        "    Returns:\n",
        "        combined_df: Combined DataFrame with all languages\n",
        "        language_counts: Dict with counts per language\n",
        "    \"\"\"\n",
        "    import glob\n",
        "\n",
        "    # Language code mapping\n",
        "    lang_files = {\n",
        "        'amh': 'amh.csv',  # Amharic\n",
        "        'arb': 'arb.csv',  # Arabic\n",
        "        'deu': 'deu.csv',  # German\n",
        "        'eng': 'eng.csv',  # English\n",
        "        'hau': 'hau.csv',  # Hausa\n",
        "        'ita': 'ita.csv',  # Italian\n",
        "        'spa': 'spa.csv',  # Spanish\n",
        "        'urd': 'urd.csv',  # Urdu\n",
        "        'zho': 'zho.csv',  # Chinese\n",
        "    }\n",
        "\n",
        "    # If no languages specified, use all\n",
        "    if languages is None:\n",
        "        languages = list(lang_files.keys())\n",
        "\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"LOADING {split.upper()} DATA - MULTILINGUAL\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Languages requested: {', '.join(languages)}\")\n",
        "    print(f\"Data directory: {data_dir}\")\n",
        "    print()\n",
        "\n",
        "    all_dataframes = []\n",
        "    language_counts = {}\n",
        "\n",
        "    for lang_code in languages:\n",
        "        file_name = lang_files.get(lang_code)\n",
        "        if file_name is None:\n",
        "            print(f\"⚠️  Warning: Unknown language code '{lang_code}', skipping...\")\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"⚠️  Warning: File not found: {file_path}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Load CSV\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['language'] = lang_code  # Add language identifier\n",
        "\n",
        "        all_dataframes.append(df)\n",
        "        language_counts[lang_code] = len(df)\n",
        "\n",
        "        print(f\"✓ Loaded {lang_code}: {len(df)} samples from {file_name}\")\n",
        "\n",
        "    # Combine all dataframes\n",
        "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TOTAL: {len(combined_df)} samples across {len(language_counts)} languages\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Show class distribution\n",
        "    if 'polarization' in combined_df.columns:\n",
        "        print(\"\\nClass Distribution:\")\n",
        "        for lang_code, count in language_counts.items():\n",
        "            lang_df = combined_df[combined_df['language'] == lang_code]\n",
        "            polarized = (lang_df['polarization'] == 1).sum()\n",
        "            non_polarized = (lang_df['polarization'] == 0).sum()\n",
        "            print(f\"  {lang_code}: Polarized={polarized}, Non-Polarized={non_polarized}\")\n",
        "\n",
        "    return combined_df, language_counts\n",
        "\n",
        "\n",
        "def generate_multilingual_predictions(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    dev_dir,\n",
        "    output_dir,\n",
        "    languages=None,\n",
        "    threshold=0.48\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate predictions for all languages in dev folder\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        dev_dir: Path to dev folder\n",
        "        output_dir: Where to save predictions\n",
        "        languages: List of language codes or None for all\n",
        "        threshold: Classification threshold\n",
        "\n",
        "    Returns:\n",
        "        all_predictions: Dict with predictions per language\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    # Language files\n",
        "    lang_files = {\n",
        "        'amh': 'amh.csv',\n",
        "        'arb': 'arb.csv',\n",
        "        'deu': 'deu.csv',\n",
        "        'eng': 'eng.csv',\n",
        "        'hau': 'hau.csv',\n",
        "        'ita': 'ita.csv',\n",
        "        'spa': 'spa.csv',\n",
        "        'urd': 'urd.csv',\n",
        "        'zho': 'zho.csv',\n",
        "    }\n",
        "\n",
        "    if languages is None:\n",
        "        languages = list(lang_files.keys())\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"GENERATING MULTILINGUAL PREDICTIONS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Languages: {', '.join(languages)}\")\n",
        "    print(f\"Dev directory: {dev_dir}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "    print(f\"Threshold: {threshold}\")\n",
        "    print()\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    all_predictions = {}\n",
        "\n",
        "    for lang_code in languages:\n",
        "        file_name = lang_files.get(lang_code)\n",
        "        if file_name is None:\n",
        "            continue\n",
        "\n",
        "        input_path = os.path.join(dev_dir, file_name)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"⚠️  Skipping {lang_code}: File not found\")\n",
        "            continue\n",
        "\n",
        "        # Output filename: pred_<lang>.csv\n",
        "        output_filename = f\"pred_{file_name}\"\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        print(f\"Processing {lang_code}...\")\n",
        "\n",
        "        # Load test data\n",
        "        test_df = pd.read_csv(input_path)\n",
        "\n",
        "        # Create dataset\n",
        "        test_dataset = PolarizationDataset(\n",
        "            test_df['text'].tolist(),\n",
        "            [0] * len(test_df),  # Dummy labels for test\n",
        "            tokenizer,\n",
        "            max_length=128\n",
        "        )\n",
        "\n",
        "        # Generate predictions\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        predictions = []\n",
        "        probabilities = []\n",
        "\n",
        "        from torch.utils.data import DataLoader\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=False,\n",
        "            collate_fn=data_collator\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                probs = torch.softmax(outputs.logits, dim=-1)[:, 1].cpu().numpy()\n",
        "                preds = (probs >= threshold).astype(int)\n",
        "\n",
        "                predictions.extend(preds)\n",
        "                probabilities.extend(probs)\n",
        "\n",
        "        # Create submission DataFrame\n",
        "        submission_df = pd.DataFrame({\n",
        "            'id': test_df['id'],\n",
        "            'text': test_df['text'],\n",
        "            'polarization': predictions,\n",
        "            'probability': probabilities\n",
        "        })\n",
        "\n",
        "        # Save predictions\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "\n",
        "        # Store results\n",
        "        all_predictions[lang_code] = submission_df\n",
        "\n",
        "        print(f\"✓ Saved {lang_code}: {len(submission_df)} predictions to {output_filename}\")\n",
        "        print(f\"  Polarized: {submission_df['polarization'].sum()}, Non-Polarized: {(submission_df['polarization']==0).sum()}\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"ALL PREDICTIONS COMPLETED!\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    return all_predictions\n"
      ],
      "metadata": {
        "id": "WHlctL7iHf1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BitLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    1.58-bit Quantized Linear Layer (BitNet)\n",
        "\n",
        "    Key Features:\n",
        "    - Weights: Ternary quantization {-1, 0, +1}\n",
        "    - Activations: 8-bit quantization [-128, 127]\n",
        "    - Straight-Through Estimator (STE) for gradient flow\n",
        "    - Lambda warmup for gradual quantization\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Initialize weights with Xavier uniform (better for deep networks)\n",
        "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        # Layer normalization before quantization (critical for stability)\n",
        "        self.layer_norm = nn.LayerNorm(in_features)\n",
        "\n",
        "        # Lambda for gradual quantization warmup (starts at 0, goes to 1)\n",
        "        self.register_buffer('lambda_val', torch.tensor(0.0))\n",
        "\n",
        "    def weight_quant(self, w):\n",
        "        \"\"\"\n",
        "        Quantize weights to ternary values {-1, 0, +1}\n",
        "        Uses round-to-nearest with scale normalization\n",
        "        \"\"\"\n",
        "        # Calculate scale factor using mean absolute value\n",
        "        scale = 1.0 / w.abs().mean().clamp_(min=1e-5)\n",
        "        # Round to nearest integer and clamp to [-1, 0, 1]\n",
        "        w_quant = (w * scale).round().clamp_(-1, 1) / scale\n",
        "        return w_quant\n",
        "\n",
        "    def activation_quant(self, x):\n",
        "        \"\"\"\n",
        "        Quantize activations to 8-bit using absmax quantization\n",
        "        Maps to [-128, 127] range\n",
        "        \"\"\"\n",
        "        # Find maximum absolute value per sample\n",
        "        scale = 127.0 / x.abs().max(dim=-1, keepdim=True).values.clamp_(min=1e-5)\n",
        "        # Quantize and dequantize\n",
        "        x_quant = (x * scale).round().clamp_(-128, 127) / scale\n",
        "        return x_quant\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply layer normalization first\n",
        "        x_norm = self.layer_norm(x)\n",
        "\n",
        "        # Get current lambda value (controls quantization strength)\n",
        "        lambda_val = self.lambda_val.item()\n",
        "\n",
        "        if self.training:\n",
        "            # During training: gradual quantization with lambda warmup\n",
        "            x_quant_full = self.activation_quant(x_norm)\n",
        "            w_quant_full = self.weight_quant(self.weight)\n",
        "\n",
        "            # Linear interpolation between full precision and quantized\n",
        "            # Lambda = 0: full precision, Lambda = 1: full quantization\n",
        "            x_mixed = x_norm * (1 - lambda_val) + x_quant_full * lambda_val\n",
        "            w_mixed = self.weight * (1 - lambda_val) + w_quant_full * lambda_val\n",
        "\n",
        "            # Straight-Through Estimator: forward with quantized, backward with original\n",
        "            x_final = x_mixed + (x_quant_full - x_mixed).detach()\n",
        "            w_final = w_mixed + (w_quant_full - w_mixed).detach()\n",
        "        else:\n",
        "            # During inference: full quantization (lambda = 1)\n",
        "            x_final = x_norm + (self.activation_quant(x_norm) - x_norm).detach()\n",
        "            w_final = self.weight + (self.weight_quant(self.weight) - self.weight).detach()\n",
        "\n",
        "        # Standard linear transformation\n",
        "        return F.linear(x_final, w_final, self.bias)"
      ],
      "metadata": {
        "id": "Y7DDaUCKiQHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BitNetBinaryClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    BitNet model for binary polarization detection\n",
        "    Architecture: BERT -> BitLinear Layers -> Classification\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name='bert-base-uncased', num_labels=2, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load pretrained BERT\n",
        "        print(f\"Loading BERT model: {model_name}\")\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        config = self.bert.config\n",
        "        self.num_labels = num_labels\n",
        "        # Freeze first 8 layers of mDeBERTa to speed up training\n",
        "        # Optional: Freeze early BERT layers for efficiency\n",
        "        # Uncomment to freeze first 8 layers (keeps last 4 trainable)\n",
        "        # for layer in self.bert.encoder.layer[:8]:\n",
        "        #     for param in layer.parameters():\n",
        "        #         param.requires_grad = False\n",
        "\n",
        "        # BitLinear classification head (2 layers for better representation)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.bit_fc1 = BitLinear(config.hidden_size, config.hidden_size // 2)\n",
        "        self.activation = nn.GELU()\n",
        "        self.bit_fc2 = BitLinear(config.hidden_size // 2, num_labels)\n",
        "\n",
        "        print(f\"Model initialized with {sum(p.numel() for p in self.parameters()):,} parameters\")\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        \"\"\"\n",
        "        Forward pass through BitNet classifier\n",
        "        \"\"\"\n",
        "        # Get encoder outputs\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        # Extract [CLS] token representation from last hidden state\n",
        "        # This works for both BERT and DeBERTa\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        # Pass through BitLinear classification head\n",
        "        x = self.bit_fc1(pooled_output)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.bit_fc2(x)\n",
        "\n",
        "        # Compute loss if labels provided\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=None,\n",
        "            attentions=None\n",
        "        )"
      ],
      "metadata": {
        "id": "REJvh3v8iZqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolarizationDataset(Dataset):\n",
        "    \"\"\"Dataset class for polarization detection\"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize with proper truncation\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=False,  # Handled by DataCollator\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Squeeze to remove batch dimension\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "id": "p53peM3Hiier"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_learning_rate(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    tokenizer,\n",
        "    start_lr=1e-10,\n",
        "    end_lr=1e-1,\n",
        "    num_iter=2000,\n",
        "    plot=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Learning Rate Finder compatible with HuggingFace transformers\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"LEARNING RATE RANGE TEST\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Testing learning rates from {start_lr} to {end_lr}\")\n",
        "    print(f\"Number of iterations: {num_iter}\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=start_lr,\n",
        "        weight_decay=0.02\n",
        "    )\n",
        "\n",
        "    # Loss function\n",
        "    criterion = FocalLoss(alpha=0.65, gamma=2.0)\n",
        "\n",
        "    # Create data loader with HuggingFace collator\n",
        "    from torch.utils.data import DataLoader\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=True,\n",
        "        collate_fn=data_collator\n",
        "    )\n",
        "\n",
        "    # Generate LR values (exponential spacing)\n",
        "    lrs = np.logspace(np.log10(start_lr), np.log10(end_lr), num_iter)\n",
        "\n",
        "    # Storage\n",
        "    losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    print(f\"\\nRunning LR Range Test...\")\n",
        "\n",
        "    data_iter = iter(train_loader)\n",
        "\n",
        "    for i, lr in enumerate(lrs):\n",
        "        # Update learning rate\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        try:\n",
        "            # Get batch - this is BatchEncoding format from HuggingFace\n",
        "            batch = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(train_loader)\n",
        "            batch = next(data_iter)\n",
        "\n",
        "        # ✅ Extract data from BatchEncoding properly\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store results\n",
        "        losses.append(loss.item())\n",
        "        learning_rates.append(lr)\n",
        "\n",
        "        # Print progress\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f\"  Step {i+1}/{num_iter}: LR = {lr:.2e}, Loss = {loss.item():.4f}\")\n",
        "\n",
        "        # Stop if loss explodes\n",
        "        if loss.item() > 100:\n",
        "            print(f\"\\nStopped early at step {i+1}: Loss exploded\")\n",
        "            break\n",
        "\n",
        "    # Find best LR (steepest negative gradient)\n",
        "    loss_gradients = np.gradient(losses)\n",
        "    best_idx = np.argmin(loss_gradients)\n",
        "    suggested_lr = learning_rates[best_idx]\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SUGGESTED LEARNING RATE: {suggested_lr:.2e}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Plot if requested\n",
        "    if plot:\n",
        "        try:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "            # Plot 1: Loss vs LR\n",
        "            axes[0].plot(learning_rates, losses, 'b-')\n",
        "            axes[0].axvline(x=suggested_lr, color='red', linestyle='--',\n",
        "                           label=f'Suggested: {suggested_lr:.2e}')\n",
        "            axes[0].set_xlabel('Learning Rate')\n",
        "            axes[0].set_ylabel('Loss')\n",
        "            axes[0].set_title('Loss vs Learning Rate')\n",
        "            axes[0].set_xscale('log')\n",
        "            axes[0].legend()\n",
        "            axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot 2: Loss gradient\n",
        "            axes[1].plot(learning_rates, loss_gradients, 'g-')\n",
        "            axes[1].axvline(x=suggested_lr, color='red', linestyle='--',\n",
        "                           label=f'Suggested: {suggested_lr:.2e}')\n",
        "            axes[1].set_xlabel('Learning Rate')\n",
        "            axes[1].set_ylabel('Loss Gradient')\n",
        "            axes[1].set_title('Loss Gradient')\n",
        "            axes[1].set_xscale('log')\n",
        "            axes[1].legend()\n",
        "            axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('lr_finder_results.png', dpi=150)\n",
        "            print(f\"\\nPlot saved to: lr_finder_results.png\")\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not create plot: {e}\")\n",
        "\n",
        "    # Store results\n",
        "    lr_results = {\n",
        "        'learning_rates': learning_rates,\n",
        "        'losses': losses,\n",
        "        'suggested_lr': suggested_lr\n",
        "    }\n",
        "\n",
        "    # Save to CSV\n",
        "    results_df = pd.DataFrame({\n",
        "        'learning_rate': learning_rates,\n",
        "        'loss': losses\n",
        "    })\n",
        "    results_df.to_csv('lr_finder_results.csv', index=False)\n",
        "    print(f\"Results saved to: lr_finder_results.csv\")\n",
        "\n",
        "    return suggested_lr, lr_results\n"
      ],
      "metadata": {
        "id": "QgNKXsBXCBGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss for handling class imbalance\n",
        "    Reference: https://arxiv.org/abs/1708.02002\n",
        "\n",
        "    Better than weighted CE for imbalanced classification because it:\n",
        "    - Focuses on hard-to-classify examples\n",
        "    - Down-weights easy examples\n",
        "    - Reduces false positives\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.65, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "\n",
        "class BitNetTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Custom trainer with:\n",
        "    - Gradual quantization warmup (lambda scheduling)\n",
        "    - Option for Weighted CE or Focal Loss for class imbalance\n",
        "    \"\"\"\n",
        "    def __init__(self, warmup_steps=1000, class_weight=None, use_focal_loss=False, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.use_focal_loss = use_focal_loss\n",
        "\n",
        "        # Handle class weights\n",
        "        if class_weight is not None:\n",
        "            self.class_weight = class_weight.to(self.args.device)\n",
        "        else:\n",
        "            self.class_weight = None\n",
        "\n",
        "        print(f\"Lambda warmup enabled: 0 -> 1 over {warmup_steps} steps\")\n",
        "\n",
        "        # Initialize loss function\n",
        "        if self.use_focal_loss:\n",
        "            self.focal_loss = FocalLoss(alpha=0.65, gamma=2.0)\n",
        "            print(f\"Using Focal Loss (alpha=0.65, gamma=2.0)\")\n",
        "        elif self.class_weight is not None:\n",
        "            print(f\"Using Weighted CE Loss with weights: {self.class_weight}\")\n",
        "        else:\n",
        "            print(f\"Using standard Cross-Entropy Loss\")\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Calculate lambda based on current training step\n",
        "        current_step = self.state.global_step\n",
        "        lambda_val = min(1.0, current_step / self.warmup_steps)\n",
        "\n",
        "        # Set lambda for all BitLinear layers\n",
        "        for module in model.modules():\n",
        "            if hasattr(module, 'lambda_val'):\n",
        "                module.lambda_val.fill_(lambda_val)\n",
        "\n",
        "        # Get labels and perform forward pass\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Compute loss based on selected method\n",
        "        if self.use_focal_loss:\n",
        "            loss = self.focal_loss(logits, labels)\n",
        "        elif self.class_weight is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weight)\n",
        "            loss = loss_fct(logits, labels)\n",
        "        else:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "3yCEKOGFinO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for binary classification\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\n",
        "        'f1_macro': f1_score(labels, preds, average='macro'),\n",
        "        'f1_binary': f1_score(labels, preds, average='binary'),\n",
        "        'accuracy': accuracy_score(labels, preds)\n",
        "    }"
      ],
      "metadata": {
        "id": "VKnCV3l3ir-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# DATA AUGMENTATION FOR LOW-RESOURCE LANGUAGES\n",
        "# ==========================================\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "from nlpaug.util import Action\n",
        "\n",
        "def augment_data_with_eda(texts, labels, languages, augmentation_factor=1):\n",
        "    \"\"\"\n",
        "    Easy Data Augmentation (EDA): Random Insertion, Swap, Deletion, Replacement\n",
        "    \n",
        "    Args:\n",
        "        texts: List of text samples\n",
        "        labels: List of labels\n",
        "        languages: List of language codes\n",
        "        augmentation_factor: How many augmented copies per sample\n",
        "    \n",
        "    Returns:\n",
        "        augmented_texts, augmented_labels, augmented_languages\n",
        "    \"\"\"\n",
        "    augmented_texts = list(texts)\n",
        "    augmented_labels = list(labels)\n",
        "    augmented_languages = list(languages)\n",
        "    \n",
        "    for i in range(len(texts)):\n",
        "        text = texts[i]\n",
        "        label = labels[i]\n",
        "        language = languages[i]\n",
        "        \n",
        "        for _ in range(augmentation_factor):\n",
        "            try:\n",
        "                # Synonym replacement (p=0.1 means 10% of non-stopwords are replaced)\n",
        "                aug = naw.SynonymAug(aug_p=0.1, lang=language if language in ['en', 'de', 'es', 'it'] else 'en')\n",
        "                augmented_text = aug.augment(text)\n",
        "                \n",
        "                if augmented_text and len(augmented_text) > 5:\n",
        "                    augmented_texts.append(augmented_text)\n",
        "                    augmented_labels.append(label)\n",
        "                    augmented_languages.append(language)\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    return augmented_texts, augmented_labels, augmented_languages\n",
        "\n",
        "\n",
        "def augment_minority_class(\n",
        "    train_df,\n",
        "    target_languages=None,\n",
        "    augmentation_factor=2\n",
        "):\n",
        "    \"\"\"\n",
        "    Augment minority class in specified languages to balance data\n",
        "    \n",
        "    Args:\n",
        "        train_df: Training dataframe with 'text', 'polarization', 'language' columns\n",
        "        target_languages: List of languages to augment (None = augment low-performing ones)\n",
        "        augmentation_factor: Number of augmented copies per minority sample\n",
        "    \n",
        "    Returns:\n",
        "        augmented_df: Dataframe with augmented data\n",
        "    \"\"\"\n",
        "    augmented_rows = []\n",
        "    \n",
        "    if target_languages is None:\n",
        "        target_languages = train_df['language'].unique()\n",
        "    \n",
        "    for lang in target_languages:\n",
        "        lang_data = train_df[train_df['language'] == lang].copy()\n",
        "        \n",
        "        # Find minority class\n",
        "        class_dist = lang_data['polarization'].value_counts()\n",
        "        minority_class = class_dist.idxmin()\n",
        "        minority_data = lang_data[lang_data['polarization'] == minority_class]\n",
        "        \n",
        "        print(f\"\\n{lang.upper()}: Augmenting minority class {minority_class}\")\n",
        "        print(f\"  Original minority samples: {len(minority_data)}\")\n",
        "        \n",
        "        for idx, row in minority_data.iterrows():\n",
        "            text = row['text']\n",
        "            \n",
        "            for aug_idx in range(augmentation_factor):\n",
        "                try:\n",
        "                    # Random synonym replacement\n",
        "                    aug = naw.SynonymAug(aug_p=0.15)\n",
        "                    augmented_text = aug.augment(text)\n",
        "                    \n",
        "                    if augmented_text and len(augmented_text) > 5 and augmented_text != text:\n",
        "                        augmented_rows.append({\n",
        "                            'text': augmented_text,\n",
        "                            'polarization': row['polarization'],\n",
        "                            'language': lang\n",
        "                        })\n",
        "                except:\n",
        "                    continue\n",
        "        \n",
        "        print(f\"  Generated augmented samples: {len([r for r in augmented_rows if r['language'] == lang])}\")\n",
        "    \n",
        "    # Combine with original data\n",
        "    augmented_df = pd.concat(\n",
        "        [train_df, pd.DataFrame(augmented_rows)],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nOriginal dataset size: {len(train_df)}\")\n",
        "    print(f\"Augmented dataset size: {len(augmented_df)}\")\n",
        "    print(f\"Samples added: {len(augmented_df) - len(train_df)}\")\n",
        "    \n",
        "    return augmented_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# LANGUAGE-SPECIFIC CLASS WEIGHTS\n",
        "# ==========================================\n",
        "\n",
        "def compute_language_class_weights(train_df):\n",
        "    \"\"\"\n",
        "    Compute class weights for each language separately based on frequency\n",
        "    \n",
        "    Args:\n",
        "        train_df: Training dataframe with 'polarization' and 'language' columns\n",
        "    \n",
        "    Returns:\n",
        "        lang_weights: Dict mapping language to class weights tensor\n",
        "    \"\"\"\n",
        "    lang_weights = {}\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"COMPUTING LANGUAGE-SPECIFIC CLASS WEIGHTS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for lang in sorted(train_df['language'].unique()):\n",
        "        lang_data = train_df[train_df['language'] == lang]\n",
        "        class_counts = lang_data['polarization'].value_counts().sort_index()\n",
        "        \n",
        "        # Compute inverse frequency weights: weight = total / (2 * count)\n",
        "        total = len(lang_data)\n",
        "        weights = {}\n",
        "        \n",
        "        for class_idx in [0, 1]:\n",
        "            count = class_counts.get(class_idx, 1)\n",
        "            weight = total / (2 * max(count, 1))\n",
        "            weights[class_idx] = weight\n",
        "        \n",
        "        # Normalize weights\n",
        "        total_weight = sum(weights.values())\n",
        "        weights = {k: v / total_weight for k, v in weights.items()}\n",
        "        \n",
        "        lang_weights[lang] = torch.tensor(\n",
        "            [weights[0], weights[1]], \n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n{lang.upper()}:\")\n",
        "        print(f\"  Non-polarized ({class_counts.get(0, 0)}): {weights[0]:.4f}\")\n",
        "        print(f\"  Polarized ({class_counts.get(1, 0)}): {weights[1]:.4f}\")\n",
        "        print(f\"  Imbalance ratio: {max(weights.values()) / min(weights.values()):.2f}x\")\n",
        "    \n",
        "    return lang_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# IMPROVED FOCAL LOSS WITH LANGUAGE AWARENESS\n",
        "# ==========================================\n",
        "\n",
        "class LanguageAwareFocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss with language-specific alpha and gamma parameters\n",
        "    Better handles class imbalance that varies across languages\n",
        "    \"\"\"\n",
        "    def __init__(self, lang_alphas=None, lang_gammas=None, reduction='mean'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            lang_alphas: Dict mapping language to alpha value (e.g., {'eng': 0.6, 'arb': 0.65})\n",
        "            lang_gammas: Dict mapping language to gamma value\n",
        "            reduction: 'mean' or 'sum'\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.lang_alphas = lang_alphas or {}\n",
        "        self.lang_gammas = lang_gammas or {}\n",
        "        self.reduction = reduction\n",
        "        self.default_alpha = 0.65\n",
        "        self.default_gamma = 2.0\n",
        "\n",
        "    def forward(self, inputs, targets, language_ids=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: Model logits (batch_size, num_classes)\n",
        "            targets: Target labels (batch_size,)\n",
        "            language_ids: Language indices for each sample (batch_size,)\n",
        "        \"\"\"\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        \n",
        "        if language_ids is not None:\n",
        "            # Apply language-specific parameters\n",
        "            alpha_values = []\n",
        "            gamma_values = []\n",
        "            \n",
        "            for lang_id in language_ids:\n",
        "                lang = language_ids[lang_id] if isinstance(language_ids, dict) else lang_id\n",
        "                alpha_values.append(self.lang_alphas.get(lang, self.default_alpha))\n",
        "                gamma_values.append(self.lang_gammas.get(lang, self.default_gamma))\n",
        "            \n",
        "            alpha = torch.tensor(alpha_values, device=inputs.device)\n",
        "            gamma = torch.tensor(gamma_values, device=inputs.device)\n",
        "        else:\n",
        "            alpha = self.default_alpha\n",
        "            gamma = self.default_gamma\n",
        "        \n",
        "        focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# UPDATED POLARIZATION DATASET WITH LANGUAGE INFO\n",
        "# ==========================================\n",
        "\n",
        "class PolarizationDatasetV2(Dataset):\n",
        "    \"\"\"\n",
        "    Enhanced dataset class for polarization detection with language tracking\n",
        "    Includes language-specific information for language-aware training\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128, languages=None, language_to_id=None):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.languages = languages if languages is not None else ['eng'] * len(texts)\n",
        "        \n",
        "        # Create language to ID mapping if not provided\n",
        "        if language_to_id is None:\n",
        "            unique_langs = sorted(set(self.languages))\n",
        "            self.language_to_id = {lang: idx for idx, lang in enumerate(unique_langs)}\n",
        "        else:\n",
        "            self.language_to_id = language_to_id\n\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        language = self.languages[idx]\n",
        "        language_id = self.language_to_id.get(language, 0)\n",
        "\n",
        "        # Tokenize with proper truncation\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=False,  # Handled by DataCollator\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Squeeze to remove batch dimension\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        item['language_id'] = torch.tensor(language_id, dtype=torch.long)\n",
        "        item['language'] = language\n",
        "\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# LANGUAGE-SPECIFIC ADAPTERS (OPTIONAL)\n",
        "# ==========================================\n",
        "# Uncomment below to use language-specific adapters\n",
        "# This requires: pip install -U adapters\n",
        "\n",
        "\"\"\"\n",
        "from adapters import AutoAdapterModel, AdapterConfig\n",
        "\n",
        "def add_language_adapters(model, languages):\n",
        "    '''Add lightweight adapter layers for each language'''\n",
        "    \n",
        "    adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
        "    \n",
        "    for lang in languages:\n",
        "        adapter_name = f\"lang_{lang}\"\n",
        "        model.add_adapter(adapter_name, config=adapter_config)\n",
        "        print(f\"✓ Added adapter for {lang}\")\n",
        "    \n",
        "    return model\n",
        "\"\"\"\n",
        "\n",
        "# Alternative: Lightweight LoRA adapters (more compatible)\n",
        "def add_language_lora_adapters(model, languages, r=8, lora_alpha=16):\n",
        "    \"\"\"\n",
        "    Add LoRA (Low-Rank Adaptation) layers for each language\n",
        "    Requires: pip install peft\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from peft import LoraConfig, get_peft_model, TaskType\n",
        "        \n",
        "        # Create base LoRA config\n",
        "        lora_config = LoraConfig(\n",
        "            r=r,\n",
        "            lora_alpha=lora_alpha,\n",
        "            target_modules=[\"query\", \"value\"],  # Target Q and V projections\n",
        "            lora_dropout=0.1,\n",
        "            bias=\"none\",\n",
        "            task_type=TaskType.SEQ_2_SEQ_LM\n",
        "        )\n",
        "        \n",
        "        # Apply LoRA to model\n",
        "        model = get_peft_model(model, lora_config)\n",
        "        \n",
        "        print(f\"✓ Added LoRA adapters (r={r})\")\n",
        "        print(f\"Trainable parameters: {model.print_trainable_parameters()}\")\n",
        "        \n",
        "        return model\n",
        "    except ImportError:\n",
        "        print(\"peft not installed. Install with: pip install peft\")\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWiAQNeoFDUs"
      },
      "source": [
        "def train_multilingual_polarization_detector_improved(\n    train_dir='/content/gdrive/MyDrive/subtask1/train',\n    languages=None,\n    model_name='microsoft/mdeberta-v3-base',\n    use_lr_finder=False,\n    use_data_augmentation=True,\n    use_language_specific_weights=True,\n    max_length=192,  # Increased from 128\n    num_epochs=6,  # Increased from 3\n    learning_rate=5e-5,  # Increased from 3e-5\n    use_adapters=False,\n    use_standard_layers=False  # If True, uses standard Linear instead of BitNet\n):\n    \"\"\"\n    IMPROVED: Train multilingual polarization detector with all enhancements\n\n    Args:\n        train_dir: Path to training data folder\n        languages: List of language codes or None for all\n        model_name: Model to use (mDeBERTa recommended)\n        use_lr_finder: Whether to run LR finder\n        use_data_augmentation: Apply EDA augmentation to minority classes\n        use_language_specific_weights: Use language-aware class weights\n        max_length: Maximum token sequence length\n        num_epochs: Number of training epochs\n        learning_rate: Initial learning rate\n        use_adapters: Add language-specific LoRA adapters\n        use_standard_layers: Replace BitNet with standard Linear layers\n    \"\"\"\n    set_seed(42)\n\n    print(\"\\n\" + \"=\"*70)\n    print(\"IMPROVED MULTILINGUAL POLARIZATION DETECTION TRAINING\")\n    print(\"=\"*70)\n    print(f\"Enhancements enabled:\")\n    print(f\"  • Data Augmentation: {use_data_augmentation}\")\n    print(f\"  • Language-specific Weights: {use_language_specific_weights}\")\n    print(f\"  • Language-specific Adapters: {use_adapters}\")\n    print(f\"  • Max Sequence Length: {max_length}\")\n    print(f\"  • Training Epochs: {num_epochs}\")\n    print(f\"  • Learning Rate: {learning_rate:.2e}\")\n    print(\"=\"*70 + \"\\n\")\n\n    # STEP 1: Load multilingual data\n    print(\"STEP 1: LOADING MULTILINGUAL DATA\")\n    print(\"=\"*70)\n\n    train_full, lang_counts = load_multilingual_data(\n        data_dir=train_dir,\n        languages=languages,\n        split='train'\n    )\n\n    # STEP 1B: Data Augmentation for minority classes\n    if use_data_augmentation:\n        print(\"\\nSTEP 1B: APPLYING DATA AUGMENTATION\")\n        print(\"=\"*70)\n\n        # Identify underrepresented languages\n        lang_sizes = train_full['language'].value_counts()\n        underrepresented = lang_sizes[lang_sizes < lang_sizes.median()].index.tolist()\n\n        print(f\"\\nLanguages marked for augmentation: {underrepresented}\")\n        train_full = augment_minority_class(\n            train_full,\n            target_languages=underrepresented,\n            augmentation_factor=2\n        )\n\n    # Stratified split preserving language distribution\n    train, val = train_test_split(\n        train_full,\n        test_size=0.2,\n        stratify=train_full[['polarization', 'language']],\n        random_state=42\n    )\n\n    print(f\"\\nTrain samples: {len(train)}\")\n    print(f\"Val samples: {len(val)}\")\n\n    # STEP 2: Initialize tokenizer and model\n    print(f\"\\n{'='*70}\")\n    print(\"STEP 2: INITIALIZING MODEL AND TOKENIZER\")\n    print(f\"{'='*70}\")\n    print(f\"Model: {model_name}\")\n    print(f\"Max Length: {max_length}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    # Create language to ID mapping\n    unique_languages = sorted(train['language'].unique())\n    language_to_id = {lang: idx for idx, lang in enumerate(unique_languages)}\n    print(f\"\\nLanguage mapping: {language_to_id}\")\n\n    # Create datasets with improved version\n    train_dataset = PolarizationDatasetV2(\n        train['text'].tolist(),\n        train['polarization'].tolist(),\n        tokenizer,\n        max_length=max_length,\n        languages=train['language'].tolist(),\n        language_to_id=language_to_id\n    )\n\n    val_dataset = PolarizationDatasetV2(\n        val['text'].tolist(),\n        val['polarization'].tolist(),\n        tokenizer,\n        max_length=max_length,\n        languages=val['language'].tolist(),\n        language_to_id=language_to_id\n    )\n\n    # Initialize model\n    if use_standard_layers:\n        print(\"\\nUsing standard Linear layers (no BitNet quantization)\")\n        model = BitNetBinaryClassifier(\n            model_name=model_name,\n            num_labels=2,\n            dropout_prob=0.3\n        )\n        # Replace BitLinear with standard Linear\n        config = model.bert.config\n        model.bit_fc1 = nn.Linear(config.hidden_size, config.hidden_size // 2)\n        model.bit_fc2 = nn.Linear(config.hidden_size // 2, 2)\n    else:\n        model = BitNetBinaryClassifier(\n            model_name=model_name,\n            num_labels=2,\n            dropout_prob=0.3  # Increased from 0.2\n        )\n\n    # Add adapters if requested\n    if use_adapters:\n        print(\"\\nAdding language-specific LoRA adapters...\")\n        model = add_language_lora_adapters(model, unique_languages, r=8)\n\n    # STEP 3: Compute language-specific class weights\n    lang_weights = None\n    if use_language_specific_weights:\n        print(f\"\\n{'='*70}\")\n        print(\"STEP 3: COMPUTING LANGUAGE-SPECIFIC CLASS WEIGHTS\")\n        print(f\"{'='*70}\")\n        lang_weights = compute_language_class_weights(train)\n\n    # STEP 4: Learning Rate Finder (optional)\n    if use_lr_finder:\n        print(f\"\\n{'='*70}\")\n        print(\"STEP 4: LEARNING RATE FINDER\")\n        print(f\"{'='*70}\")\n\n        suggested_lr, lr_results = find_optimal_learning_rate(\n            model=model,\n            train_dataset=train_dataset,\n            val_dataset=val_dataset,\n            tokenizer=tokenizer,\n            start_lr=1e-10,\n            end_lr=1e-1,\n            num_iter=2000,\n            plot=True\n        )\n\n        final_lr = suggested_lr\n        print(f\"\\nUsing Learning Rate: {final_lr:.2e}\")\n    else:\n        final_lr = learning_rate\n        print(f\"\\nUsing Learning Rate: {final_lr:.2e}\")\n\n    # STEP 5: Train model with improved configuration\n    print(f\"\\n{'='*70}\")\n    print(\"STEP 5: TRAINING MODEL (IMPROVED)\")\n    print(f\"{'='*70}\")\n\n    # Calculate total training steps for proper scheduling\n    num_train_samples = len(train_dataset)\n    batch_size = 32\n    num_steps_per_epoch = (num_train_samples + batch_size - 1) // batch_size\n    total_steps = num_steps_per_epoch * num_epochs\n    warmup_steps = int(0.1 * total_steps)  # 10% warmup\n\n    print(f\"\\nTraining Configuration:\")\n    print(f\"  Total training steps: {total_steps}\")\n    print(f\"  Warmup steps: {warmup_steps}\")\n    print(f\"  Batch size: {batch_size}\")\n    print(f\"  Epochs: {num_epochs}\")\n\n    # Improved training arguments with cosine scheduling\n    training_args = TrainingArguments(\n        output_dir='./results_multilingual_improved',\n        num_train_epochs=num_epochs,\n        per_device_train_batch_size=32,\n        per_device_eval_batch_size=64,\n        gradient_accumulation_steps=1,  # Can set to 2-4 for effective batch doubling\n        warmup_steps=warmup_steps,\n        learning_rate=final_lr,\n        weight_decay=0.01,  # Reduced from 0.02\n        lr_scheduler_type='cosine',  # IMPROVED: Cosine annealing\n        logging_dir='./logs_multilingual_improved',\n        logging_steps=50,\n        eval_strategy='steps',\n        eval_steps=100,  # More frequent evaluation\n        save_strategy='steps',\n        save_steps=100,\n        load_best_model_at_end=True,\n        metric_for_best_model='f1_macro',\n        greater_is_better=True,\n        save_total_limit=3,  # Keep 3 best checkpoints\n        report_to='none',\n        seed=42,\n        fp16=torch.cuda.is_available(),\n        dataloader_pin_memory=True,\n        optim='adamw_8bit' if torch.cuda.is_available() else 'adamw_torch',  # Memory efficient\n    )\n\n    # Custom metrics computation with per-language tracking\n    def compute_metrics_improved(eval_pred):\n        \"\"\"Compute metrics including per-language F1 scores\"\"\"\n        predictions, labels = eval_pred\n        predictions = np.argmax(predictions, axis=1)\n\n        # Overall metrics\n        metrics = {\n            'f1_macro': f1_score(labels, predictions, average='macro', zero_division=0),\n            'f1_binary': f1_score(labels, predictions, average='binary', zero_division=0),\n            'accuracy': accuracy_score(labels, predictions),\n            'precision': precision_score(labels, predictions, average='macro', zero_division=0),\n            'recall': recall_score(labels, predictions, average='macro', zero_division=0),\n        }\n\n        return metrics\n\n    # Use language-aware trainer if using language-specific weights\n    trainer = BitNetTrainer(\n        warmup_steps=warmup_steps,\n        class_weight=None,  # Will use language-specific weights in loss\n        use_focal_loss=True,\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics_improved,\n        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n        callbacks=[\n            EarlyStoppingCallback(\n                early_stopping_patience=5,\n                early_stopping_threshold=0.001\n            )\n        ]\n    )\n\n    print(\"\\nStarting training...\")\n    results = trainer.train()\n\n    return model, tokenizer, trainer, results, train, val, language_to_id\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_to_drive(model, tokenizer, save_dir, model_config, threshold=None):\n",
        "    \"\"\"\n",
        "    Save complete model to Google Drive for later inference\n",
        "\n",
        "    Args:\n",
        "        model: Trained BitNetBinaryClassifier\n",
        "        tokenizer: AutoTokenizer\n",
        "        save_dir: Path in Google Drive\n",
        "        model_config: Dict with model configuration\n",
        "        threshold: Optimal threshold (optional)\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Saving model to {save_dir}...\")\n",
        "\n",
        "    # 1. Save PyTorch model state dict\n",
        "    torch.save(\n",
        "        model.state_dict(),\n",
        "        os.path.join(save_dir, 'pytorch_model.bin')\n",
        "    )\n",
        "    print(\"✓ Saved PyTorch model weights\")\n",
        "\n",
        "    # 2. Save tokenizer (HuggingFace format)\n",
        "    tokenizer.save_pretrained(save_dir)\n",
        "    print(\"✓ Saved tokenizer\")\n",
        "\n",
        "    # 3. Save model configuration\n",
        "    config_with_threshold = {\n",
        "        **model_config,\n",
        "        'optimal_threshold': threshold,\n",
        "        'saved_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(save_dir, 'model_config.json'), 'w') as f:\n",
        "        json.dump(config_with_threshold, f, indent=2)\n",
        "    print(\"✓ Saved model configuration\")\n",
        "\n",
        "    # 4. Save training metrics (if available)\n",
        "    metrics_file = os.path.join(save_dir, 'training_metrics.txt')\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        f.write(f\"Model Configuration:\\n\")\n",
        "        f.write(f\"Model: {model_config['model_name']}\\n\")\n",
        "        f.write(f\"Dropout: {model_config['dropout_prob']}\\n\")\n",
        "        f.write(f\"Optimal Threshold: {threshold}\\n\")\n",
        "        f.write(f\"Saved: {config_with_threshold['saved_date']}\\n\")\n",
        "    print(\"✓ Saved training metrics\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"MODEL SUCCESSFULLY SAVED TO GOOGLE DRIVE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Location: {save_dir}\")\n",
        "    print(f\"Files saved:\")\n",
        "    print(f\"  - pytorch_model.bin (model weights)\")\n",
        "    print(f\"  - tokenizer files (tokenizer_config.json, vocab.txt, etc.)\")\n",
        "    print(f\"  - model_config.json (configuration)\")\n",
        "    print(f\"  - training_metrics.txt (metadata)\")\n"
      ],
      "metadata": {
        "id": "kkzKex0cBKvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_from_drive(save_dir):\n",
        "    \"\"\"\n",
        "    Load trained model from Google Drive for inference\n",
        "\n",
        "    Args:\n",
        "        save_dir: Path where model was saved in Google Drive\n",
        "\n",
        "    Returns:\n",
        "        model: Loaded BitNetBinaryClassifier\n",
        "        tokenizer: Loaded tokenizer\n",
        "        config: Model configuration dict\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "\n",
        "    print(f\"Loading model from {save_dir}...\")\n",
        "\n",
        "    # 1. Load model configuration\n",
        "    config_path = os.path.join(save_dir, 'model_config.json')\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "    print(f\"✓ Loaded configuration\")\n",
        "\n",
        "    # 2. Initialize model with same architecture\n",
        "    model = BitNetBinaryClassifier(\n",
        "        model_name=config['model_name'],\n",
        "        num_labels=config['num_labels'],\n",
        "        dropout_prob=config['dropout_prob']\n",
        "    )\n",
        "    print(f\"✓ Initialized model architecture\")\n",
        "\n",
        "    # 3. Load model weights\n",
        "    model_path = os.path.join(save_dir, 'pytorch_model.bin')\n",
        "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    print(f\"✓ Loaded model weights\")\n",
        "\n",
        "    # 4. Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "    print(f\"✓ Loaded tokenizer\")\n",
        "\n",
        "    # Move model to appropriate device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    print(f\"✓ Model moved to {device}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"MODEL SUCCESSFULLY LOADED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model: {config['model_name']}\")\n",
        "    print(f\"Optimal Threshold: {config.get('optimal_threshold', 'Not saved')}\")\n",
        "    print(f\"Saved Date: {config.get('saved_date', 'Unknown')}\")\n",
        "\n",
        "    return model, tokenizer, config\n"
      ],
      "metadata": {
        "id": "XSw-q5kaBQl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_polarization(text, model, tokenizer, return_probabilities=True):\n",
        "    \"\"\"\n",
        "    Make predictions on new text\n",
        "\n",
        "    Args:\n",
        "        text: Input text string\n",
        "        model: Trained BitNet model\n",
        "        tokenizer: BERT tokenizer\n",
        "        return_probabilities: If True, return probabilities along with prediction\n",
        "\n",
        "    Returns:\n",
        "        prediction: 0 (Not Polarized) or 1 (Polarized)\n",
        "        confidence: Probability of being polarized (if return_probabilities=True)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        )\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        pred = torch.argmax(probs, dim=-1).item()\n",
        "        confidence = probs[0][1].item()  # Probability of being polarized\n",
        "\n",
        "    if return_probabilities:\n",
        "        return pred, confidence\n",
        "    return pred"
      ],
      "metadata": {
        "id": "wqx6sTaRjAgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_only_mode(\n",
        "    model_dir,\n",
        "    test_file='dev_eng.csv',\n",
        "    output_file='dev_predictions_inference.csv',\n",
        "    threshold=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Run inference without training - load model from Drive\n",
        "\n",
        "    Args:\n",
        "        model_dir: Path to saved model in Google Drive\n",
        "        test_file: Test data CSV file\n",
        "        output_file: Output predictions CSV\n",
        "        threshold: Custom threshold (uses saved optimal if None)\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"INFERENCE-ONLY MODE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load model from Google Drive\n",
        "    model, tokenizer, config = load_model_from_drive(model_dir)\n",
        "\n",
        "    # Use saved optimal threshold if not provided\n",
        "    if threshold is None:\n",
        "        threshold = config.get('optimal_threshold', 0.48)\n",
        "        print(f\"Using saved optimal threshold: {threshold}\")\n",
        "    else:\n",
        "        print(f\"Using custom threshold: {threshold}\")\n",
        "\n",
        "    # Generate predictions\n",
        "    print(f\"\\nGenerating predictions for {test_file}...\")\n",
        "    submission = create_submission(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        test_file=test_file,\n",
        "        output_file=output_file,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"INFERENCE COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Predictions saved to: {output_file}\")\n",
        "\n",
        "    return submission\n"
      ],
      "metadata": {
        "id": "V8hSdV5MBTwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(model, tokenizer, test_file='dev_eng.csv', output_file='dev_predictions.csv', threshold=0.48):\n",
        "    \"\"\"\n",
        "    Create predictions for dev/test dataset with custom threshold\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        test_file: Path to test file\n",
        "        output_file: Output CSV file\n",
        "        threshold: Decision threshold (default 0.48)\n",
        "\n",
        "    Returns:\n",
        "        submission: DataFrame with predictions\n",
        "    \"\"\"\n",
        "    print(f\"\\nCreating predictions from {test_file}...\")\n",
        "    print(f\"Using threshold: {threshold}\")\n",
        "\n",
        "    # Load test data\n",
        "    test = pd.read_csv(test_file)\n",
        "    print(f\"Test samples: {len(test)}\")\n",
        "\n",
        "    # Create dataset with dummy labels\n",
        "    test_dataset = PolarizationDataset(\n",
        "        test['text'].tolist(),\n",
        "        [0] * len(test),  # Dummy labels\n",
        "        tokenizer,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # Create trainer for prediction\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    print(\"Generating predictions...\")\n",
        "    prediction_output = trainer.predict(test_dataset)\n",
        "    raw_predictions = prediction_output.predictions\n",
        "\n",
        "    # Convert to tensor and handle shape\n",
        "    if not isinstance(raw_predictions, torch.Tensor):\n",
        "        raw_predictions = torch.tensor(raw_predictions)\n",
        "\n",
        "    # Ensure correct shape (num_samples, num_labels)\n",
        "    if raw_predictions.dim() == 1:\n",
        "        # If 1D, reshape to (num_samples, num_labels)\n",
        "        raw_predictions = raw_predictions.reshape(-1, 2)\n",
        "    elif raw_predictions.shape[1] != 2:\n",
        "        # If shape is unexpected, try to fix it\n",
        "        raw_predictions = raw_predictions.reshape(len(test), -1)[:, :2]\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = F.softmax(raw_predictions, dim=1)\n",
        "    pred_probs = probs[:, 1].numpy()  # Probability of polarized class\n",
        "\n",
        "    # Apply threshold\n",
        "    pred_labels = (pred_probs >= threshold).astype(int)\n",
        "\n",
        "    # Create submission dataframe\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test['id'],\n",
        "        'text': test['text'],\n",
        "        'predicted_polarization': pred_labels,\n",
        "        'polarization_probability': pred_probs\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    submission.to_csv(output_file, index=False)\n",
        "    print(f\"\\nPredictions saved to: {output_file}\")\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\nPrediction Statistics:\")\n",
        "    print(f\"  Non-polarized (0): {(pred_labels == 0).sum()} ({(pred_labels == 0).sum() / len(pred_labels) * 100:.2f}%)\")\n",
        "    print(f\"  Polarized (1): {(pred_labels == 1).sum()} ({(pred_labels == 1).sum() / len(pred_labels) * 100:.2f}%)\")\n",
        "    print(f\"  Mean probability: {pred_probs.mean():.4f}\")\n",
        "    print(f\"  Median probability: {np.median(pred_probs):.4f}\")\n",
        "\n",
        "    return submission\n"
      ],
      "metadata": {
        "id": "K3Zlg5W-84VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIUR_0fFKkvu"
      },
      "source": [
        "def find_optimal_threshold(model, tokenizer, val_file='train_eng.csv'):\n",
        "    \"\"\"\n",
        "    Find optimal threshold for F1 Macro maximization\n",
        "\n",
        "    Uses the validation split from training data to find best threshold\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        val_file: Training file (will use 20% validation split)\n",
        "\n",
        "    Returns:\n",
        "        best_threshold: Optimal threshold\n",
        "        best_f1_macro: Best F1 Macro achieved\n",
        "        results_df: Full results DataFrame\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FINDING OPTIMAL THRESHOLD FOR F1 MACRO\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load and split data same way as training\n",
        "    full_data = pd.read_csv(val_file)\n",
        "    _, val_data = train_test_split(\n",
        "        full_data,\n",
        "        test_size=0.2,\n",
        "        stratify=full_data['polarization'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Validation samples: {len(val_data)}\")\n",
        "\n",
        "    # Create dataset\n",
        "    val_dataset = PolarizationDataset(\n",
        "        val_data['text'].tolist(),\n",
        "        val_data['polarization'].tolist(),\n",
        "        tokenizer,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    predictions = trainer.predict(val_dataset)\n",
        "    raw_predictions = predictions.predictions\n",
        "\n",
        "    # Convert to probabilities\n",
        "    if not isinstance(raw_predictions, torch.Tensor):\n",
        "        raw_predictions = torch.tensor(raw_predictions)\n",
        "\n",
        "    if raw_predictions.dim() == 1:\n",
        "        raw_predictions = raw_predictions.reshape(-1, 2)\n",
        "\n",
        "    probs = F.softmax(raw_predictions, dim=1)[:, 1].numpy()\n",
        "    true_labels = val_data['polarization'].values\n",
        "\n",
        "    # Test thresholds\n",
        "    print(\"\\nTesting thresholds from 0.30 to 0.70...\")\n",
        "    thresholds = np.arange(0.30, 0.71, 0.01)\n",
        "\n",
        "    results = []\n",
        "    for thresh in thresholds:\n",
        "        pred_labels = (probs >= thresh).astype(int)\n",
        "\n",
        "        f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
        "        f1_binary = f1_score(true_labels, pred_labels, average='binary', zero_division=0)\n",
        "        precision = (pred_labels[pred_labels == 1] == true_labels[pred_labels == 1]).sum() / max(pred_labels.sum(), 1)\n",
        "        recall = (pred_labels[true_labels == 1] == 1).sum() / max((true_labels == 1).sum(), 1)\n",
        "        accuracy = (pred_labels == true_labels).sum() / len(true_labels)\n",
        "\n",
        "        results.append({\n",
        "            'threshold': thresh,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_binary': f1_binary,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'accuracy': accuracy\n",
        "        })\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Find best threshold\n",
        "    best_idx = results_df['f1_macro'].idxmax()\n",
        "    best_result = results_df.loc[best_idx]\n",
        "\n",
        "    # Print top 5 thresholds\n",
        "    print(\"\\nTop 5 thresholds by F1 Macro:\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Threshold':<12} {'F1 Macro':<12} {'F1 Binary':<12} {'Precision':<12} {'Recall':<12}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    top_5 = results_df.nlargest(5, 'f1_macro')\n",
        "    for _, row in top_5.iterrows():\n",
        "        print(f\"{row['threshold']:.2f}         {row['f1_macro']:.4f}       \"\n",
        "              f\"{row['f1_binary']:.4f}       {row['precision']:.4f}       {row['recall']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"OPTIMAL THRESHOLD FOUND\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Best Threshold: {best_result['threshold']:.2f}\")\n",
        "    print(f\"F1 Macro: {best_result['f1_macro']:.4f}\")\n",
        "    print(f\"F1 Binary: {best_result['f1_binary']:.4f}\")\n",
        "    print(f\"Precision: {best_result['precision']:.4f}\")\n",
        "    print(f\"Recall: {best_result['recall']:.4f}\")\n",
        "    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "\n",
        "    # Save full results\n",
        "    results_df.to_csv('threshold_optimization_results.csv', index=False)\n",
        "    print(\"\\nFull results saved to: threshold_optimization_results.csv\")\n",
        "\n",
        "    return best_result['threshold'], best_result['f1_macro'], results_df\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference_examples(model, tokenizer):\n",
        "    \"\"\"Test model on example texts\"\"\"\n",
        "\n",
        "    test_examples = [\n",
        "        \"This politician is destroying our country with terrible policies!\",\n",
        "        \"I believe we need better education and healthcare systems.\",\n",
        "        \"Those people are all criminals and should be deported immediately!\",\n",
        "        \"Research shows that renewable energy can reduce carbon emissions.\",\n",
        "        \"They're trying to take away our rights and freedoms!\",\n",
        "        \"The weather forecast predicts rain tomorrow afternoon.\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INFERENCE EXAMPLES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, text in enumerate(test_examples, 1):\n",
        "        pred, confidence = predict_polarization(text, model, tokenizer)\n",
        "        label = \"Polarized\" if pred == 1 else \"Not Polarized\"\n",
        "        print(f\"\\n{i}. Text: {text}\")\n",
        "        print(f\"   Prediction: {label}\")\n",
        "        print(f\"   Confidence: {confidence:.3f}\")"
      ],
      "metadata": {
        "id": "ZsjWq2yAjbSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TT5Vb4WRFDUu",
        "outputId": "c78151ea-452b-4a4a-d112-75f595bf3855"
      },
      "source": [
        "if __name__ == \"__main__\":\n\n    # Configuration\n    TRAIN_DIR = '/content/gdrive/MyDrive/subtask1/train'\n    DEV_DIR = '/content/gdrive/MyDrive/subtask1/dev'\n    OUTPUT_DIR = '/content/gdrive/MyDrive/subtask1/predictions'\n    MODEL_SAVE_DIR = '/content/gdrive/MyDrive/SemevalModels/bitnet_multilingual_improved'\n\n    INFERENCE_MODE = False  # Set to True to skip training\n    USE_LR_FINDER = False   # Set to True to find optimal LR\n\n    # Language selection (None = all languages)\n    LANGUAGES = None  # Or specify: ['eng', 'arb', 'deu', 'spa']\n\n    # ========== IMPROVED PARAMETERS ==========\n    USE_DATA_AUGMENTATION = True  # Enable EDA for minority classes\n    USE_LANGUAGE_SPECIFIC_WEIGHTS = True  # Enable language-aware class weights\n    USE_ADAPTERS = False  # Set to True to use LoRA adapters\n    USE_STANDARD_LAYERS = False  # Set to True to remove BitNet quantization\n    MAX_LENGTH = 192  # Increased from 128\n    NUM_EPOCHS = 6  # Increased from 3\n    LEARNING_RATE = 5e-5  # Increased from 3e-5\n    # ==========================================\n\n    if INFERENCE_MODE:\n        # ==========================================\n        # INFERENCE ONLY\n        # ==========================================\n        print(\"\\n\" + \"=\"*70)\n        print(\"INFERENCE-ONLY MODE - MULTILINGUAL (IMPROVED)\")\n        print(\"=\"*70 + \"\\n\")\n\n        # Load model\n        model, tokenizer, config = load_model_from_drive(MODEL_SAVE_DIR)\n        threshold = config.get('optimal_threshold', 0.48)\n\n        # Generate predictions for all languages\n        predictions = generate_multilingual_predictions(\n            model=model,\n            tokenizer=tokenizer,\n            dev_dir=DEV_DIR,\n            output_dir=OUTPUT_DIR,\n            languages=LANGUAGES,\n            threshold=threshold\n        )\n\n    else:\n        # ==========================================\n        # FULL TRAINING WORKFLOW (IMPROVED)\n        # ==========================================\n        print(\"\\n\" + \"=\"*70)\n        print(\"FULL MULTILINGUAL TRAINING WORKFLOW (WITH ALL IMPROVEMENTS)\")\n        print(\"=\"*70 + \"\\n\")\n\n        # STEP 1: Train model with all improvements\n        model, tokenizer, trainer, train_results, train_data, val_data, lang_to_id = train_multilingual_polarization_detector_improved(\n            train_dir=TRAIN_DIR,\n            languages=LANGUAGES,\n            model_name='microsoft/mdeberta-v3-base',\n            use_lr_finder=USE_LR_FINDER,\n            use_data_augmentation=USE_DATA_AUGMENTATION,\n            use_language_specific_weights=USE_LANGUAGE_SPECIFIC_WEIGHTS,\n            max_length=MAX_LENGTH,\n            num_epochs=NUM_EPOCHS,\n            learning_rate=LEARNING_RATE,\n            use_adapters=USE_ADAPTERS,\n            use_standard_layers=USE_STANDARD_LAYERS\n        )\n\n        # STEP 2: Find optimal threshold\n        print(\"\\n\" + \"=\"*70)\n        print(\"FINDING OPTIMAL THRESHOLD\")\n        print(\"=\"*70)\n\n        best_threshold, best_f1_macro, threshold_results = find_optimal_threshold(\n            model, \n            tokenizer,\n            val_file=TRAIN_DIR.replace('train', 'train')  # Use training data for validation\n        )\n\n        # STEP 3: Find per-language optimal thresholds\n        print(\"\\n\" + \"=\"*70)\n        print(\"FINDING PER-LANGUAGE OPTIMAL THRESHOLDS\")\n        print(\"=\"*70)\n\n        # This is a new addition for per-language threshold optimization\n        lang_thresholds = {}\n        for lang in val_data['language'].unique():\n            lang_val = val_data[val_data['language'] == lang]\n\n            if len(lang_val) > 50:  # Only if enough samples\n                lang_val_dataset = PolarizationDatasetV2(\n                    lang_val['text'].tolist(),\n                    lang_val['polarization'].tolist(),\n                    tokenizer,\n                    max_length=MAX_LENGTH,\n                    languages=lang_val['language'].tolist(),\n                    language_to_id=lang_to_id\n                )\n\n                # Get predictions\n                from transformers import Trainer\n                temp_trainer = Trainer(\n                    model=model,\n                    data_collator=DataCollatorWithPadding(tokenizer)\n                )\n\n                predictions = temp_trainer.predict(lang_val_dataset)\n                probs = F.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n\n                # Find best threshold for this language\n                best_lang_f1 = 0\n                best_lang_thresh = 0.5\n\n                for thresh in np.arange(0.3, 0.71, 0.01):\n                    pred_labels = (probs >= thresh).astype(int)\n                    lang_f1 = f1_score(lang_val['polarization'].values, pred_labels, average='macro', zero_division=0)\n\n                    if lang_f1 > best_lang_f1:\n                        best_lang_f1 = lang_f1\n                        best_lang_thresh = thresh\n\n                lang_thresholds[lang] = {\n                    'threshold': best_lang_thresh,\n                    'f1_macro': best_lang_f1,\n                    'samples': len(lang_val)\n                }\n\n                print(f\"\\n{lang.upper()}:\")\n                print(f\"  Optimal Threshold: {best_lang_thresh:.3f}\")\n                print(f\"  F1 Macro: {best_lang_f1:.4f}\")\n                print(f\"  Validation Samples: {len(lang_val)}\")\n\n        # STEP 4: Save model\n        print(\"\\n\" + \"=\"*70)\n        print(\"SAVING MODEL\")\n        print(\"=\"*70)\n\n        model_config = {\n            'model_name': 'microsoft/mdeberta-v3-base',\n            'num_labels': 2,\n            'dropout_prob': 0.3,\n            'max_length': MAX_LENGTH,\n            'improvements': {\n                'data_augmentation': USE_DATA_AUGMENTATION,\n                'language_specific_weights': USE_LANGUAGE_SPECIFIC_WEIGHTS,\n                'cosine_scheduling': True,\n                'extended_epochs': NUM_EPOCHS,\n                'learning_rate': LEARNING_RATE,\n            }\n        }\n\n        save_model_to_drive(\n            model,\n            tokenizer,\n            MODEL_SAVE_DIR,\n            model_config,\n            threshold=best_threshold\n        )\n\n        # STEP 5: Generate predictions on dev set\n        print(\"\\n\" + \"=\"*70)\n        print(\"GENERATING PREDICTIONS ON DEV SET\")\n        print(\"=\"*70)\n\n        # Create submission for all languages\n        submissions = generate_multilingual_predictions(\n            model=model,\n            tokenizer=tokenizer,\n            dev_dir=DEV_DIR,\n            output_dir=OUTPUT_DIR,\n            languages=LANGUAGES,\n            threshold=best_threshold,\n            lang_thresholds=lang_thresholds\n        )\n\n        # STEP 6: Test on example texts\n        print(\"\\n\" + \"=\"*70)\n        print(\"TESTING ON EXAMPLE TEXTS\")\n        print(\"=\"*70)\n\n        test_inference_examples(model, tokenizer)\n\n        print(\"\\n\" + \"=\"*70)\n        print(\"TRAINING COMPLETE!\")\n        print(\"=\"*70)\n        print(f\"\\nModel saved to: {MODEL_SAVE_DIR}\")\n        print(f\"Predictions saved to: {OUTPUT_DIR}\")\n        print(f\"\\nBest Overall Threshold: {best_threshold:.3f}\")\n        print(f\"Best Overall F1 Macro: {best_f1_macro:.4f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FULL MULTILINGUAL TRAINING WORKFLOW\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "MULTILINGUAL POLARIZATION DETECTION TRAINING\n",
            "======================================================================\n",
            "\n",
            "STEP 1: LOADING MULTILINGUAL DATA\n",
            "======================================================================\n",
            "======================================================================\n",
            "LOADING TRAIN DATA - MULTILINGUAL\n",
            "======================================================================\n",
            "Languages requested: amh, arb, deu, eng, hau, ita, spa, urd, zho\n",
            "Data directory: /content/gdrive/MyDrive/subtask1/train\n",
            "\n",
            "✓ Loaded amh: 3332 samples from amh.csv\n",
            "✓ Loaded arb: 3380 samples from arb.csv\n",
            "✓ Loaded deu: 3180 samples from deu.csv\n",
            "✓ Loaded eng: 2676 samples from eng.csv\n",
            "✓ Loaded hau: 3651 samples from hau.csv\n",
            "✓ Loaded ita: 3334 samples from ita.csv\n",
            "✓ Loaded spa: 3305 samples from spa.csv\n",
            "✓ Loaded urd: 2849 samples from urd.csv\n",
            "✓ Loaded zho: 4280 samples from zho.csv\n",
            "\n",
            "======================================================================\n",
            "TOTAL: 29987 samples across 9 languages\n",
            "======================================================================\n",
            "\n",
            "Class Distribution:\n",
            "  amh: Polarized=2518, Non-Polarized=814\n",
            "  arb: Polarized=1512, Non-Polarized=1868\n",
            "  deu: Polarized=1512, Non-Polarized=1668\n",
            "  eng: Polarized=1002, Non-Polarized=1674\n",
            "  hau: Polarized=392, Non-Polarized=3259\n",
            "  ita: Polarized=1368, Non-Polarized=1966\n",
            "  spa: Polarized=1660, Non-Polarized=1645\n",
            "  urd: Polarized=1976, Non-Polarized=873\n",
            "  zho: Polarized=2121, Non-Polarized=2159\n",
            "\n",
            "Train samples: 23989\n",
            "Val samples: 5998\n",
            "\n",
            "======================================================================\n",
            "STEP 2: INITIALIZING MODEL\n",
            "======================================================================\n",
            "Model: microsoft/mdeberta-v3-base\n",
            "Loading BERT model: microsoft/mdeberta-v3-base\n",
            "Freezing first 8 encoder layers for faster training...\n",
            "Model initialized with 278,517,122 parameters\n",
            "\n",
            "Using default Learning Rate: 3.00e-05\n",
            "\n",
            "======================================================================\n",
            "STEP 4: TRAINING MODEL\n",
            "======================================================================\n",
            "Lambda warmup enabled: 0 -> 1 over 1000 steps\n",
            "Using Focal Loss (alpha=0.65, gamma=2.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2250/2250 33:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Binary</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.172900</td>\n",
              "      <td>0.096298</td>\n",
              "      <td>0.698580</td>\n",
              "      <td>0.686469</td>\n",
              "      <td>0.699066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>0.087824</td>\n",
              "      <td>0.735098</td>\n",
              "      <td>0.705463</td>\n",
              "      <td>0.738413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.087933</td>\n",
              "      <td>0.738109</td>\n",
              "      <td>0.696411</td>\n",
              "      <td>0.744748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.080017</td>\n",
              "      <td>0.756860</td>\n",
              "      <td>0.734484</td>\n",
              "      <td>0.758920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.084700</td>\n",
              "      <td>0.081627</td>\n",
              "      <td>0.757374</td>\n",
              "      <td>0.747787</td>\n",
              "      <td>0.757753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.084200</td>\n",
              "      <td>0.080192</td>\n",
              "      <td>0.760538</td>\n",
              "      <td>0.757104</td>\n",
              "      <td>0.760587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.084300</td>\n",
              "      <td>0.080116</td>\n",
              "      <td>0.762089</td>\n",
              "      <td>0.755822</td>\n",
              "      <td>0.762254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.080534</td>\n",
              "      <td>0.761587</td>\n",
              "      <td>0.761189</td>\n",
              "      <td>0.761587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.081100</td>\n",
              "      <td>0.080275</td>\n",
              "      <td>0.759920</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.759920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.081200</td>\n",
              "      <td>0.080199</td>\n",
              "      <td>0.760585</td>\n",
              "      <td>0.759866</td>\n",
              "      <td>0.760587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.087000</td>\n",
              "      <td>0.079909</td>\n",
              "      <td>0.763943</td>\n",
              "      <td>0.755363</td>\n",
              "      <td>0.764255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.082400</td>\n",
              "      <td>0.079940</td>\n",
              "      <td>0.764435</td>\n",
              "      <td>0.755756</td>\n",
              "      <td>0.764755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.082300</td>\n",
              "      <td>0.079699</td>\n",
              "      <td>0.763428</td>\n",
              "      <td>0.752621</td>\n",
              "      <td>0.763921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.079866</td>\n",
              "      <td>0.761674</td>\n",
              "      <td>0.749912</td>\n",
              "      <td>0.762254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.077200</td>\n",
              "      <td>0.079895</td>\n",
              "      <td>0.761837</td>\n",
              "      <td>0.750044</td>\n",
              "      <td>0.762421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINDING OPTIMAL THRESHOLD\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "FINDING OPTIMAL THRESHOLD FOR F1 MACRO\n",
            "======================================================================\n",
            "Validation samples: 1200\n",
            "Generating predictions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing thresholds from 0.30 to 0.70...\n",
            "\n",
            "Top 5 thresholds by F1 Macro:\n",
            "----------------------------------------------------------------------\n",
            "Threshold    F1 Macro     F1 Binary    Precision    Recall      \n",
            "----------------------------------------------------------------------\n",
            "0.49         0.7667       0.7678       0.7189       0.8238\n",
            "0.50         0.7640       0.7587       0.7283       0.7918\n",
            "0.53         0.7640       0.7429       0.7646       0.7224\n",
            "0.52         0.7625       0.7482       0.7456       0.7509\n",
            "0.51         0.7622       0.7532       0.7336       0.7740\n",
            "\n",
            "======================================================================\n",
            "OPTIMAL THRESHOLD FOUND\n",
            "======================================================================\n",
            "Best Threshold: 0.49\n",
            "F1 Macro: 0.7667\n",
            "F1 Binary: 0.7678\n",
            "Precision: 0.7189\n",
            "Recall: 0.8238\n",
            "Accuracy: 0.7667\n",
            "\n",
            "Full results saved to: threshold_optimization_results.csv\n",
            "\n",
            "Optimal threshold: 0.49\n",
            "Expected F1 Macro: 0.7667\n",
            "\n",
            "======================================================================\n",
            "SAVING MODEL TO GOOGLE DRIVE\n",
            "======================================================================\n",
            "Saving model to /content/gdrive/MyDrive/SemevalModels/bitnet_multilingual...\n",
            "✓ Saved PyTorch model weights\n",
            "✓ Saved tokenizer\n",
            "✓ Saved model configuration\n",
            "✓ Saved training metrics\n",
            "\n",
            "============================================================\n",
            "MODEL SUCCESSFULLY SAVED TO GOOGLE DRIVE!\n",
            "============================================================\n",
            "Location: /content/gdrive/MyDrive/SemevalModels/bitnet_multilingual\n",
            "Files saved:\n",
            "  - pytorch_model.bin (model weights)\n",
            "  - tokenizer files (tokenizer_config.json, vocab.txt, etc.)\n",
            "  - model_config.json (configuration)\n",
            "  - training_metrics.txt (metadata)\n",
            "\n",
            "======================================================================\n",
            "GENERATING DEV PREDICTIONS - ALL LANGUAGES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "GENERATING MULTILINGUAL PREDICTIONS\n",
            "======================================================================\n",
            "Languages: amh, arb, deu, eng, hau, ita, spa, urd, zho\n",
            "Dev directory: /content/gdrive/MyDrive/subtask1/dev\n",
            "Output directory: /content/gdrive/MyDrive/subtask1/predictions\n",
            "Threshold: 0.49000000000000016\n",
            "\n",
            "Processing amh...\n",
            "✓ Saved amh: 166 predictions to pred_amh.csv\n",
            "  Polarized: 146, Non-Polarized: 20\n",
            "Processing arb...\n",
            "✓ Saved arb: 169 predictions to pred_arb.csv\n",
            "  Polarized: 86, Non-Polarized: 83\n",
            "Processing deu...\n",
            "✓ Saved deu: 159 predictions to pred_deu.csv\n",
            "  Polarized: 71, Non-Polarized: 88\n",
            "Processing eng...\n",
            "✓ Saved eng: 133 predictions to pred_eng.csv\n",
            "  Polarized: 40, Non-Polarized: 93\n",
            "Processing hau...\n",
            "✓ Saved hau: 182 predictions to pred_hau.csv\n",
            "  Polarized: 18, Non-Polarized: 164\n",
            "Processing ita...\n",
            "✓ Saved ita: 166 predictions to pred_ita.csv\n",
            "  Polarized: 88, Non-Polarized: 78\n",
            "Processing spa...\n",
            "✓ Saved spa: 165 predictions to pred_spa.csv\n",
            "  Polarized: 85, Non-Polarized: 80\n",
            "Processing urd...\n",
            "✓ Saved urd: 142 predictions to pred_urd.csv\n",
            "  Polarized: 107, Non-Polarized: 35\n",
            "Processing zho...\n",
            "✓ Saved zho: 214 predictions to pred_zho.csv\n",
            "  Polarized: 122, Non-Polarized: 92\n",
            "\n",
            "======================================================================\n",
            "ALL PREDICTIONS COMPLETED!\n",
            "======================================================================\n",
            "Output directory: /content/gdrive/MyDrive/subtask1/predictions\n",
            "\n",
            "======================================================================\n",
            "MULTILINGUAL TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Model saved to: /content/gdrive/MyDrive/SemevalModels/bitnet_multilingual\n",
            "Predictions saved to: /content/gdrive/MyDrive/subtask1/predictions\n",
            "Optimal threshold: 0.49\n",
            "Validation F1 Macro: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# UTILITIES FOR PER-LANGUAGE EVALUATION\n",
        "# ==========================================\n",
        "\n",
        "def generate_multilingual_predictions(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    dev_dir,\n",
        "    output_dir,\n",
        "    languages=None,\n",
        "    threshold=0.49,\n",
        "    lang_thresholds=None,\n",
        "    max_length=192\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate predictions for all language dev files with optional language-specific thresholds\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        dev_dir: Directory with dev CSV files\n",
        "        output_dir: Output directory for predictions\n",
        "        languages: List of language codes (None for all)\n",
        "        threshold: Default threshold\n",
        "        lang_thresholds: Dict with language-specific thresholds\n",
        "        max_length: Max sequence length\n",
        "    \"\"\"\n",
        "    import glob\n",
        "    import os\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # If languages not specified, find all dev files\n",
        "    if languages is None:\n",
        "        dev_files = glob.glob(os.path.join(dev_dir, '*.csv'))\n",
        "        languages = [os.path.basename(f).split('_')[-1].replace('.csv', '') for f in dev_files]\n",
        "    \n",
        "    all_submissions = {}\n",
        "    lang_thresholds = lang_thresholds or {}\n",
        "    \n",
        "    print(f\"\\nGenerating predictions for {len(languages)} languages...\\n\")\n",
        "    \n",
        "    for lang in languages:\n",
        "        dev_file = os.path.join(dev_dir, f'dev_{lang}.csv')\n",
        "        \n",
        "        if not os.path.exists(dev_file):\n",
        "            print(f\"⚠ File not found: {dev_file}\")\n",
        "            continue\n",
        "        \n",
        "        # Load dev data\n",
        "        dev_data = pd.read_csv(dev_file)\n",
        "        \n",
        "        # Create dataset\n",
        "        dev_dataset = PolarizationDatasetV2(\n",
        "            dev_data['text'].tolist(),\n",
        "            [0] * len(dev_data),  # Dummy labels\n",
        "            tokenizer,\n",
        "            max_length=max_length,\n",
        "            languages=[lang] * len(dev_data)\n",
        "        )\n",
        "        \n",
        "        # Get predictions\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            data_collator=DataCollatorWithPadding(tokenizer)\n",
        "        )\n",
        "        \n",
        "        predictions = trainer.predict(dev_dataset)\n",
        "        probs = F.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "        \n",
        "        # Use language-specific threshold if available, else use default\n",
        "        if lang in lang_thresholds:\n",
        "            thresh = lang_thresholds[lang]['threshold']\n",
        "            print(f\"{lang.upper()}: Using language-specific threshold {thresh:.3f}\")\n",
        "        else:\n",
        "            thresh = threshold\n",
        "            print(f\"{lang.upper()}: Using default threshold {thresh:.3f}\")\n",
        "        \n",
        "        pred_labels = (probs >= thresh).astype(int)\n",
        "        \n",
        "        # Create submission\n",
        "        submission = pd.DataFrame({\n",
        "            'id': dev_data['id'],\n",
        "            'polarization': pred_labels\n",
        "        })\n",
        "        \n",
        "        output_file = os.path.join(output_dir, f'dev_predictions_{lang}.csv')\n",
        "        submission.to_csv(output_file, index=False)\n",
        "        all_submissions[lang] = submission\n",
        "        \n",
        "        print(f\"  ✓ Saved to {output_file}\")\n",
        "        print(f\"    Polarized: {(pred_labels == 1).sum()}/{len(pred_labels)}\")\n",
        "    \n",
        "    return all_submissions\n",
        "\n",
        "\n",
        "def evaluate_per_language(model, tokenizer, val_data, lang_to_id, max_length=192):\n",
        "    \"\"\"\n",
        "    Evaluate model performance per language\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        val_data: Validation dataframe\n",
        "        lang_to_id: Language to ID mapping\n",
        "        max_length: Max sequence length\n",
        "    \n",
        "    Returns:\n",
        "        per_lang_metrics: Dict with metrics per language\n",
        "    \"\"\"\n",
        "    per_lang_metrics = {}\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"PER-LANGUAGE EVALUATION\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    for lang in sorted(val_data['language'].unique()):\n",
        "        lang_val = val_data[val_data['language'] == lang]\n",
        "        \n",
        "        if len(lang_val) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Create dataset\n",
        "        lang_dataset = PolarizationDatasetV2(\n",
        "            lang_val['text'].tolist(),\n",
        "            lang_val['polarization'].tolist(),\n",
        "            tokenizer,\n",
        "            max_length=max_length,\n",
        "            languages=lang_val['language'].tolist(),\n",
        "            language_to_id=lang_to_id\n",
        "        )\n",
        "        \n",
        "        # Get predictions\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            data_collator=DataCollatorWithPadding(tokenizer)\n",
        "        )\n",
        "        \n",
        "        predictions = trainer.predict(lang_dataset)\n",
        "        probs = F.softmax(torch.tensor(predictions.predictions), dim=1)\n",
        "        pred_labels = torch.argmax(probs, dim=1).numpy()\n",
        "        true_labels = lang_val['polarization'].values\n",
        "        \n",
        "        # Compute metrics\n",
        "        metrics = {\n",
        "            'f1_macro': f1_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
        "            'f1_binary': f1_score(true_labels, pred_labels, average='binary', zero_division=0),\n",
        "            'accuracy': accuracy_score(true_labels, pred_labels),\n",
        "            'precision': precision_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
        "            'recall': recall_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
        "            'samples': len(lang_val)\n",
        "        }\n",
        "        \n",
        "        per_lang_metrics[lang] = metrics\n",
        "        \n",
        "        print(f\"{lang.upper()}:\")\n",
        "        print(f\"  Samples: {metrics['samples']}\")\n",
        "        print(f\"  F1 Macro: {metrics['f1_macro']:.4f}\")\n",
        "        print(f\"  F1 Binary: {metrics['f1_binary']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\\n\")\n",
        "    \n",
        "    # Compute average across languages\n",
        "    avg_f1_macro = np.mean([m['f1_macro'] for m in per_lang_metrics.values()])\n",
        "    print(f\"\\nAverage F1 Macro (across all languages): {avg_f1_macro:.4f}\")\n",
        "    print(f\"=\"*70)\n",
        "    \n",
        "    return per_lang_metrics\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}